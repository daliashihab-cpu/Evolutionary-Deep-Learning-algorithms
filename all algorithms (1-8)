Algorithm 1: Data Loading and Preprocessing
Input: Raw CSV files (Normal_data.csv, metasploitable-2.csv, OVS.csv)
Output: Processed datasets (X_train, y_train, X_val, y_val, X_test, y_test), Input shape
ALGORITHM: Preprocess_Dataset()
BEGIN
    // Phase 1: Data Loading and Cleaning
    1. Define REMOVED_COLUMNS = ["Flow ID", "Src IP", "Dst IP", "Timestamp", "Src Port", "Dst Port"]
    2. Load benign_data from "Normal_data.csv"
    3. Load attack_data from "metasploitable-2.csv"
    4. Load OVS from "OVS.csv"
    5. For each dataset: remove null values and drop REMOVED_COLUMNS
    // Phase 2: Dataset Integration
    6. Concatenate all datasets into unified dataframe dataframes
    7. Separate features: X ← dataframes.drop (columns=['Label'])
    8. Separate labels: y ← dataframes['Label']
    // Phase 3: Feature and Label Processing
    9. Apply StandardScaler to normalize feature matrix X
    10. Encode categorical labels y using LabelEncoder
    // Phase 4: Data Partitioning
    11. Split X, y into X_train (70%) and X_temp, y_temp (30%) using stratified sampling
    12. Split X_temp, y_temp into X_test (67%) and X_val, y_val (33%)
    13. Convert all labels to one-hot encoding using to_categorical
    // Phase 6: Return Processed Data
    14. Return X_train, y_train, X_val, y_val, X_test, y_test, input_shape
END


Algorithm 2: GA optimizer (Evolutionary Hybrid CNN-LSTM Optimization)
Input: Preprocessed data and GA parameters (population_size, generations).
Output: The best-found neural network architecture and its performance.
BEGIN
    // Phase 1: Initialization
    1. Initialize population using Initialize_Population()
    2. Set generation = 0
    3. Initialize statistics tracking variables
    // Phase 2: Initial Population Evaluation
    4. FOR each individual in population DO
       4.1. Build model using individual's chromosome
       4.2. fitness = Fitness_Evaluation(individual, X_train, y_train, X_val, y_val)
       4.3. Record evaluation statistics
    // Phase 3: Generation Loop
    5. FOR generation = 1 to max_generations DO
    // Phase 4: Evolution Step
       5.1. new_population = Population_Evolution (population)
    // Phase 5: New Individual Evaluation
       5.2. FOR each new individual in new_population DO
            5.2.1. IF individual not yet evaluated THEN
             Build model and evaluate fitness
         5.2.2. Record evaluation statistics
    // Phase 6: Statistics Update
       5.3. current_best = individual with maximum fitness
       5.4. Record generation statistics
       5.5. Update population = new_population
    // Phase 7: Final Evaluation
    6. best_individual = individual with highest fitness across all generations
    7. Evaluate best_individual on test set
    8. Generate comprehensive results report
    9. Return results dictionary with best individual and statistics
END



 Algorithm 3: Chromosome Encoding and Individual Initialization
Input: Predefined hyperparameter search spaces
Output: Individual I representing neural network architecture
ALGORITHM: Initialize_Individual()
BEGIN
    // Phase 1: Hyperparameter Initialization
    1. Initialize parameters dictionary:
        1.1 learning_rate ← random_choice([0.0001, 0.0005, 0.001, 0.005])
        1.2 pool_type ← random_choice(['max', 'average'])
        1.3 conv_dropout_rate ← random_choice([0.2, 0.3, 0.4])
        1.4 lstm_dropout_rate ← random_choice([0.1, 0.2, 0.3])
        1.5 conv_kernel ← random_choice([1, 3, 5])
        1.6 conv_stride ← 1
        1.7 conv_padding ← 'same'
        1.8 cnn_activation ← random_choice(['Relu', 'sigmoid', 'tanh', 'leaky_Relu', 'pRelu'])
        1.9 lstm_activation ← random_choice(['sigmoid', 'tanh'])
    // Phase 2: Architecture Generation
    2. num_conv_blocks ← random_int(1, 4)
    3. num_lstm_blocks ← random_int(1, 2)
    4. Initialize empty architecture list
    // Phase 3: Convolutional Blocks Construction
    5. For i ← 1 to num_conv_blocks do
        5.1 Append conv_block: {'type': 'conv_block', 'filters': random_choice([32, 64, 128, 256, 512]),
             'kernel_size': conv_kernel, 'stride': conv_stride, 'padding': conv_padding,
             'pool_type': pool_type, 'dropout_rate': conv_dropout_rate, 'activation': cnn_activation}
    // Phase 4: LSTM Blocks Construction
    6. For i ← 1 to num_lstm_blocks do
        6.1 Append lstm_block: {'type': 'lstm_block', 'units': random_choice([16, 32, 64]),
            'dropout_rate': lstm_dropout_rate, 'return_sequences': true, 'activation': lstm_activation}
    // Phase 5: Individual Creation
    7. Create individual I with:
        7.1 I.genes ← {'architecture': architecture}
        7.2 I.parameters ← parameters_dictionary
        7.3 I.fitness ← 0.0
        7.4 I.model ← null
    8. Return individual I
END



Algorithm 4: Fitness Evaluation	
Input: Individual I, Training data (X_train, y_train), Validation data (X_val, y_val)
Output: Fitness score, Performance metrics
ALGORITHM: Evaluate_Fitness(I, X_train, y_train, X_val, y_val)
BEGIN
    // Phase 1: Model Construction
   1. Build neural network model from I's chromosome encoding
   2. Compile model with Adam optimizer using I.parameters['learning_rate']
    // Phase 2: Model Training
   3. Train model on X_train, y_train for fixed epochs
    // Phase 3: Model Evaluation
    4. Evaluate trained model on validation set X_val, y_val
   5. Calculate validation accuracy as fitness score
   6. Calculate precision, recall, F1-score metrics
    // Phase 4: Result Return
   7. Return fitness score and performance metrics
END





Algorithm 5: Tournament Selection
Input: Population P, Tournament size k = 2
Output: Selected parents
ALGORITHM: Tournament_Selection(P, k)
BEGIN
    // Phase 1: Initialization
    1. Initialize empty parents list
    // Phase 2: Parent Selection
    2. For i ← 1 to len(P) do
        2.1 Select k random individuals from P as contestants
        2.2 Evaluate fitness of each contestant
        2.3 Choose individual with maximum fitness
        2.4 Add winner to parents list
    // Phase 3: Return Results
    3. Return parents list
END





Algorithm 6: Single-Point Crossover
Input: Parent1 P1, Parent2 P2, Crossover rate crossover_rate
Output: Child individual
ALGORITHM: Crossover(P1, P2, crossover_rate)
BEGIN
    // Phase 1: Crossover Probability Check
    1. If random() > crossover_rate then
        1.1 Return random_choice([P1, P2])
    // Phase 2: Architecture Preparation
    2. arch1 ← P1.genes['architecture']
    3. arch2 ← P2.genes['architecture']
    4. min_len ← min(len(arch1), len(arch2))
    // Phase 3: Crossover Feasibility Check
    5. If min_len ≤ 1 then
        5.1 Return random_choice([P1, P2])
    // Phase 4: Crossover Execution
    6. crossover_point ← random_int(1, min_len - 1)
    7. child_arch ← arch1[0:crossover_point] + arch2[crossover_point:]
    // Phase 5: Child Creation
    8. Return new Individual with {'architecture': child_arch}
END





Algorithm 7: Mutation Operation
Input: Individual I, Mutation rate mutation_rate
Output: Mutated individual
ALGORITHM: Mutate(I, mutation_rate)
BEGIN
    // Phase 1: Mutation Probability Check
    1. If random() > mutation_rate then
        1.1 Return I // No mutation applied
    // Phase 2: Mutation Type Selection
    2. mutation_type ← random_choice(['add_layer', 'remove_layer', 'change_parameter', 'modify_layer'])
    // Phase 3: Mutation Application
    3. Switch (mutation_type)
        Case 'add_layer': Insert random layer at randomposition
        Case 'remove_layer': Remove random layer (if architecture length > 2)
        Case 'change_parameter': Modify random hyperparameter value
        Case 'modify_layer': Change filters/units in random layer
    // Phase 4: Return Mutated Individual
    4. Return mutated individual I
END





Algorithm 8: Population Evolution
Input: Current population P, Elitism rate elitism_rate, Mutation rate mutation_rate, Crossover rate crossover_rate
Output: New population P_new
ALGORITHM: Evolve_Population(P, elitism_rate, mutation_rate, crossover_rate)
BEGIN
    // Phase 1: Elitism Selection
    1. Sort P by fitness in descending order
    2. elite_count ← max(1, ceil(elitism_rate × len(P)))
    3. P_new ← P[0:elite_count]  // Preserve best individuals
    // Phase 2: Parent Selection
    4. parents ← Tournament_Selection(P, 2)
    // Phase 3: Offspring Generation
    5. While len(P_new) < len(P) do
        5.1 Select parent1, parent2 from parents
        5.2 child ← Crossover(parent1, parent2, crossover_rate)
        5.3 child ← Mutate(child, mutation_rate)
        5.4 Append child to P_new
    // Phase 4: Return New Population
    6. Return P_new
END

